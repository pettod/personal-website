<!doctype html>
<html lang="en" data-bs-theme="auto" style="height: 100%;">
  <head><script src="assets/js/color-modes.js"></script>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <title>Peter Todorov</title>
    <link rel="icon" href="assets/pt_icon_dark_small.png" type="image/x-icon">
    <link href="assets/dist/css/bootstrap.min.css" rel="stylesheet">

    <style>
      .aspect-ratio-keeper {
        position: relative;
        width: 100%;
        padding-bottom: 56.25%; /* 16:9 aspect ratio */
        overflow: hidden;
      }
      .aspect-ratio-keeper iframe {
        position: absolute;
        width: 100%;
        height: 100%;
        border: 0;
      }
      .bd-placeholder-img {
        font-size: 1.125rem;
        text-anchor: middle;
        -webkit-user-select: none;
        -moz-user-select: none;
        user-select: none;
      }

      @media (min-width: 768px) {
        .bd-placeholder-img-lg {
          font-size: 3.5rem;
        }
      }

      .nav-scroller {
        position: relative;
        z-index: 2;
        height: 2.75rem;
        overflow-y: hidden;
      }

      .nav-scroller .nav {
        display: flex;
        flex-wrap: nowrap;
        padding-bottom: 1rem;
        margin-top: -1px;
        overflow-x: auto;
        text-align: center;
        white-space: nowrap;
        -webkit-overflow-scrolling: touch;
      }

      .sticky {
        position: -webkit-sticky;
        position: sticky;
        position: absolute;
        bottom: 0;
        width: 100%;
      }

      a {
        text-decoration: none;
      }

      div.background {
        background: linear-gradient(rgba(255,255,255,0.4), rgba(255,255,255,0.4)), url('assets/alps_small.jpg');
        background-size: cover;
      }
    </style>
    
    <!-- Custom styles for this template -->
    <link href="assets/dist/css/custom.css" rel="stylesheet">
  </head>
  <body style="height: 100%;">

<!-- NAVBAR -->
<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
  <div class="container">
    <span class="nav-item"><a class="nav-link" href="/"><img width="28" height="28" src="assets/pt_icon_light.png" onmouseover="this.src='assets/pt_icon_lighter.png';" onmouseout="this.src='assets/pt_icon_light.png';"></a></span>
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarsExample08" aria-controls="navbarsExample08" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    
    <div class="collapse navbar-collapse justify-content-md-center" id="navbarsExample08">
      <ul class="navbar-nav">
        <li class="nav-item" style="padding-right: 125px;"><a class="nav-link" href="/">Intro</a></li>
        <li class="nav-item" style="padding-right: 125px;"><a class="nav-link" href="experience">Experience</a></li>
        <li class="nav-item" style="padding-right: 125px;"><a class="nav-link" href="projects">Projects</a></li>
        <li class="nav-item"><a class="nav-link" href="education">Education</a></li>
      </ul>
    </div>
  </div>
</nav>

<main>

  <!-- Top headline -->
  <div class="background position-relative overflow-hidden p-3 p-md-5 m-md-3 text-center bg-body-tertiary">
    <div class="col-md-6 p-lg-5 mx-auto my-5">
      <h1 class="display-3 fw-bold">Projects</h1>
    </div>
  </div>

  <!-- The first 2 projects -->
  <div class="d-md-flex flex-md-equal w-100 my-md-3 ps-md-3">
    <div class="me-md-3 pt-3 px-3 pt-md-5 px-md-5 text-center overflow-hidden" style="background-color: rgb(245, 245, 245);">
      <div class="my-3 py-3">
        <h2 class="display-5">Deepfake detection</h2>
        <img width="100%" src="https://github.com/pettod/deepfake-recognition-kaggle/assets/33998401/f15c348e-7b6c-40af-8f16-48699016f3cd">
        <p class="lead" style="text-align: justify;">
          Deepfake techniques, which present realistic AI-generated videos of people doing and saying fictional things, have the potential to have a significant impact on how people determine the legitimacy of information presented online.
          These content generation and modification technologies may affect the quality of public discourse and the safeguarding of human rights â€” especially given that deepfakes may be used maliciously as a source of misinformation, manipulation, harassment, and persuasion.
          <br><br>
          I created a deep learning model to identify videos with facial or voice manipulations.
          The pipeline from input to output was as follows:
        </p>
        <ol class="lead" style="text-align: left;">
          <li>Decode .mp4 video into frames</li>
          <li>Detect faces from multiple frames</li>
          <li>Cluster different humans in a video</li>
          <li>Remove outliers that are not real humans</li>
          <li>Classify the video by using multiple faces from different video frames</li>
        </ol>
        <p class="lead" style="text-align: justify;">
          The challenge lied in how multi-step the classification had to be.
          Before being able to classify the video, had to create a face detection algorithm.
          There was a time limit so the face detection had to be fast but also accurate and not every model was able to meet these requirements.
          Also, in some of the videos there were multiple people present.
          Obviously, you cannot mess the different faces because that would easily lead to a fake prediction.
          So clustering was needed.
          Then sometimes the face detection picked face looking areas such as a pillow with eyes and a mouth or a face picture on a wall.
          These also had to be filtered out to avoid misleading the classification model.
          Finally, it was time for the classification model research in which, in the end, I concatenated 9 faces to an input image and fed it to the model.
        </p>
        <p class="lead" style="text-align: left; font-size: small;">
          *Video detection from the public dataset: <a href="https://arxiv.org/abs/2006.07397">https://arxiv.org/abs/2006.07397</a>
        </p>
      </div>
    </div>
    <div class="me-md-3 pt-3 px-3 pt-md-5 px-md-5 text-center overflow-hidden" style="background-color: rgb(245, 245, 245);">
      <div class="my-3 py-3">
        <h2 class="display-5">Package delivery optimization</h2>
        <img width="100%" src="https://github.com/pettod/delivery-routing/assets/33998401/8bda2271-aa07-48fe-8a4d-fd0f64ebcc97">
        <p class="lead" style="text-align: justify;">
          Challenged myself on learning how complex vehicle routing really is.
          The underlying problem is to minimize the traveling distance by taking into account constraints and changing environment.
          The simplest form of minimizing the distance without any constraints is called <a href="https://en.wikipedia.org/wiki/Travelling_salesman_problem">Traveling Salesperson Problem</a> (TSP).
          Here are some numbers to understand the complexity of TSP:
        </p>
        <ul class="lead" style="text-align: left;">
          <li>With 4 locations there are 6 possible routes</li>
          <li>With 11 locations there are 362,880 possible routes</li>
          <li>With 21 locations there are 2,432,902,008,176,640,000 possible routes</li>
        </ul>
        <p class="lead" style="text-align: justify;">
          Adding constraints to the routing problem further complicates the optimization.
          Constraints of the problem include, for example, vehicle capacity, vehicle refill points, traffic jams, cancelled deliveries, or product type limitations.
          I coded a solution taking into account the following constraints:
        </p>
        <ul class="lead" style="text-align: left;">
          <li>Minimize traveling distance</li>
          <li>N number of vehicles</li>
          <li>M number of packages</li>
          <li>Delivery deadlines of the packages</li>
          <li>Driver's working hours</li>
          <li>Driver's maximum single delivery distance</li>
          <li>Driver's mandatory lunch break</li>
        </ul>
      </div>
    </div>
  </div>

  <!-- The second 2 projects -->
  <div class="d-md-flex flex-md-equal w-100 my-md-3 ps-md-3">
    <div class="text-bg-dark me-md-3 pt-3 px-3 pt-md-5 px-md-5 text-center overflow-hidden">
      <div class="my-3 p-3">
        <h2 class="display-5">Prostate cancer grade assessment</h2>
        <img width="100%" src="https://github.com/pettod/personal-website/assets/33998401/ac116f86-61a6-4a3a-934e-5fd22da48c1a">
        <p class="lead" style="text-align: justify;">
          With more than 1 million new diagnoses reported every year, prostate cancer (PCa) is the second most common cancer among males worldwide that results in more than 350,000 deaths annually.
          The key to decreasing mortality is developing more precise diagnostics.
          <br><br>
          I created a deep learning model for diagnosing PCa from high-resolution images (average of 800 Mpx per image, maximum size >4000 Mpx).
          <br><br>
          Achieved validation kappa score 0.91 (6 ISUP grades in the Gleason grading system).
          Segmented cell with normal, healthy, stroma and Gleason scores from 3 to 5.
          Classified by using as large tissue area as possible.
        </p>
        <p class="lead" style="text-align: left; font-size: small;">
          *Image segmentation from the public dataset: <a href="https://www.nature.com/articles/s41591-021-01620-2">https://www.nature.com/articles/s41591-021-01620-2</a>
        </p>
      </div>
    </div>
    <div class="text-bg-dark me-md-3 pt-3 px-3 pt-md-5 px-md-5 text-center overflow-hidden">
      <div class="my-3 p-3">
        <h2 class="display-5">Motion prediction for autonomous vehicles</h2>
        <img width="100%" src="https://github.com/pettod/personal-website/assets/33998401/d2cbc66a-544d-48ff-9a47-cd885208982e">
        <p class="lead" style="text-align: justify;">
          Deep learning model for an autonomous vehicle to predict the movement of traffic agents such as cars, cyclists, and pedestrians.
          The target was to predict future trajectory from a given vector of (x,y) coordinates of the past trajectory.
          <br><br>
          By converting the coordinates to a bird eye view image, the approach of dealing with vector data was changed to image to image problem resulting in higher accuracy.
        </p>
        <p class="lead" style="text-align: left; font-size: small;">
          *Image simulated from the public dataset: <a href="https://arxiv.org/abs/2006.14480">https://arxiv.org/abs/2006.14480</a>
        </p>
      </div>
    </div>
  </div>

  <!-- The third 2 projects -->
  <div class="d-md-flex flex-md-equal w-100 my-md-3 ps-md-3">
    <div class="me-md-3 pt-3 px-3 pt-md-5 px-md-5 text-center overflow-hidden" style="background-color: rgb(245, 245, 245);">
      <div class="my-3 py-3">
        <h2 class="display-5">Molecular translation</h2>
        <img width="100%" src="https://github.com/pettod/bms-molecular-translation/assets/33998401/7d1d3d97-3660-4169-ae1d-75bbb0c1a828">
        <p class="lead" style="text-align: justify;">
          Sometimes the best and easiest tools are still pen and paper.
          Organic chemists frequently draw out molecular work with the <a href="https://en.wikipedia.org/wiki/Skeletal_formula">Skeletal formula</a>, a structural notation used for centuries.
          Recent publications are also annotated with machine-readable chemical descriptions (<a href="https://en.wikipedia.org/wiki/International_Chemical_Identifier">InChI</a>), but there are decades of scanned documents that can't be automatically searched for specific chemical depictions.
          To speed up research and development efforts, an automated recognition of optical chemical structures will be helpful.
          <br><br>
          I created a deep learning model to translate chemical images to InChI text.
        </p>
        <p class="lead" style="text-align: left; font-size: small;">
          *Image sample from the public dataset: <a href="https://www.kaggle.com/competitions/bms-molecular-translation/data">https://www.kaggle.com/competitions/bms-molecular-translation/data</a>
        </p>
      </div>
    </div>
    <div class="me-md-3 pt-3 px-3 pt-md-5 px-md-5 text-center overflow-hidden" style="background-color: rgb(245, 245, 245);">
      <div class="my-3 py-3">
        <h2 class="display-5">Charuco corner detection</h2>
        <img width="100%" src="https://github.com/pettod/charuco-corner-detection/raw/master/document_images/detected_charuco_markers.gif">
        <p class="lead" style="text-align: justify;">
          Tool for camera calibration to detect checkerboard corners with corner identifications.
          It is especially helpful for multi-camera calibration where all the cameras cannot see the whole checkerboard.
          By knowing the corner identifications, one can use images with partly visible checkerboards for camera calibration.
          <br><br>
          Used Python OpenCV and embedded it into Matlab as well.
        </p>
      </div>
    </div>
  </div>

  <!-- The fourth 2 projects -->
  <div class="d-md-flex flex-md-equal w-100 my-md-3 ps-md-3">
    <div class="text-bg-dark me-md-3 pt-3 px-3 pt-md-5 px-md-5 overflow-hidden">
      <div class="my-3 py-3">
        <h2 class="display-5 text-center">GPU usage visualization</h2>
        <div class="aspect-ratio-keeper">
          <iframe src="https://www.youtube.com/embed/qLBvez84VoA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
        </div>
        <p class="lead" style="text-align: justify;">
          Better visuals of <code style="color: rgb(74, 222, 66);">nvidia-smi</code> command.
          What <code style="color: white;">nvidia-smi</code> command does is it shows the GPU utilization and memory usage in numbers in a terminal window.
          It is not an intuitive view to understand the complete state of a GPU server.
          What does this visualization tool then provide:
        </p>
        <ul class="lead" style="text-align: left;">
          <li>Fast understanding of the state of multiple GPU servers
            <ul>
              <li>View of unlimited number of servers on a single page</li>
            </ul>
          </li>
          <li>Real-time monitoring web dashboard</li>
          <li>User specific statistics</li>
          <li>User sorted GPU programs and their execution times</li>
        </ul>
        <p class="lead" style="text-align: justify;">
          With the software, it is easier for the machine learning team to distribute workload evenly and stop training experiments which are not needed anymore.
          <br><br>
          Used technologies: Python, Flask, HTML, CSS, JS, Highcharts, Shell, and threading.
        </p>
      </div>
    </div>
    <div class="text-bg-dark me-md-3 pt-3 px-3 pt-md-5 px-md-5 overflow-hidden">
      <div class="my-3 p-3">
        <h2 class="display-5 text-center">Remote device control - web platform</h2>
        <div class="aspect-ratio-keeper">
          <iframe src="https://www.youtube.com/embed/drcwjqq63-M" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
        </div>
        <p class="lead" style="text-align: justify;">
          Turning electric devices (up to 2kW) on/off remotely, also known as home automation.
          Being able to control your electric devices remotely might help you save time of not transporting to your home, cottage or office.
          <br><br>
          I created a platform where users can login with Google account authentication and access multiple locations which to control remotely.
          <br><br>
          Overview of the tech:
        </p>
        <ul class="lead" style="text-align: left;">
          <li>Relay card control through the GPIO pins of Raspberry Pi</li>
          <li>MongoDB for user registration and session management</li>
          <li>Routing between client, proxy server, backend server, and a terminal device</li>
          <li>The terminal device controls a relay card that turns the devices either on or off</li>
          <li>Used Node.js, Flask, HTML, JS, CSS, Python, and MongoDB</li>
        </ul>
      </div>
    </div>
  </div>
  
</main>

<script src="assets/dist/js/bootstrap.bundle.min.js"></script>
  </body>
</html>
